# 《Ray Tracing in One Weekend》阶段总结
> 九层之台，起于累土

[Ray Tracing in One Weekend系列](https://raytracing.github.io/)是非常好的光线追踪入门教程。它深入浅出的讲解了光线追踪的核心理念，并且会阶段性的将结果呈现出来。

这里阶段性的总结我在阅读该系列的第一本书，即[Ray Tracing in One Weekend](https://raytracing.github.io/books/RayTracingInOneWeekend.html)(后面简称**OneWeekend**)的时候，心中的一些小小想法。

## 一些基础
### 什么是光线追踪
光线追踪(Ray Tracing)，和路径追踪(Path Tracing)有很多相似之处，它的最基础的内容，就是计算光线从起始点（人眼、或者相机的传感器），穿过屏幕上的每个像素，沿着这个方向在场景中和物体交互（反射、吸收、折射），将最终得到的颜色信息输出给对应像素得到最终图像的技术。

### 光线追踪和光栅化技术
这里先介绍一下传统的光栅化技术。

光栅化技术是将三维场景中的模型分解成网格（常见的是三角形网格），根据网格顶点位置和属性进行差值计算，得到最终图像。它大概分为下面几个步骤：
1. 模型变换：**将模型进行三维变换**，最终转换到特定坐标系中（一般是最终是屏幕坐标系）。
2. 裁剪：将屏幕之外的网格**裁切**掉。
3. 光栅化：**将三角形网格投到屏幕上**，根据三角形的顶点信息进行插值计算，确定屏幕每个像素点的颜色和深度等信息。
4. 隐藏面剔除：将在其他网格背后的面**剔除**。
5. 着色：对每个像素点进行**着色**，根据材质信息计算各种效果。

光栅化是非常成熟的技术，但是近年来光线追踪技术却异常火热，归根结底还是由于光栅化的局限性，尤其是它很难处理光线在场景中多次反射的情况，导致最终效果的真实性很难再进一步。

相比较于光栅化技术，光线追踪能得到更加真实的表现效果，尤其是光线反射和折射的部分，当然缺点是需要消耗更多的资源有着更多的硬件要求。

## 旅途第一步
那作为刚刚出生在光线追踪新手村的我们，最开始应该做什么呢？根据OneWeekend的指引，一开始我们并不会就追求实时的光线追踪效果，这对于软渲染来说是一个比较难达到的效果，我们将每次渲染放到一张图片里面，通过这张离线渲染的方式查看追踪效果。（OneWeekend里面一开始便是介绍写入ppm格式的教程，这里我不多介绍。）

然后，我们需要构建基础的数学类，比如向量类vec3，以及向量的各种数学能力（如乘法、长度计算、点乘叉乘等等）。同时在OneWeekend中，点(point3)和颜色(color)其实和vec3是同一个类，只是叫法不同。

## 数学是主武器
我们定义**射线类(ray)**，它由射出位置(origin)和射出方向(dir)组成。

另外，我们也定义场景中的物体类，由最基础的**球体(Sphere)**开始，它由球心(center)和球的半径(radius)组成。

光线追踪的关键，就是判断一道光线是否和物体相交，在此基础上才能有后续的效果处理。那么如何判断射线是否和球体相交呢，其实就是将射线的数学表达式带入球体的表达式，判断是否有解，且这个解是否在射线的区间内（比如说得到的一个解若是在射线的相反方向，那也是不符合的）。这个步骤其实和物理的碰撞检测有点类似。

想要深入学习光线追踪，**数学是主武器**。

在获取到相交点之后，可以计算出相交点的法线，通过物体的材质和法线来处理光线的进行折射、反射等不同的状态。

反射或者折射的光线，经过**衰减(Attenuation)**后，光线会进行下一段的旅程，射向另一个方向，我们也需要将下一次的光线传输结果考虑进来。并且，我们会在光线追踪的时候设定一个最大的反射次数，在这个反射次数的结果就不考虑在内了。

## 拒绝狗牙
光线追踪会对每个像素发出射线并计算最终的颜色。如果这个点过少的话很容易在物体边缘出现锯齿，也就是所谓的*狗牙*。这是因为在物体边缘的像素可能是多个颜色的中和，并不单纯是其中一种颜色。

光线追踪也需要**抗锯齿**，做法是通过在像素内随机选择多个点，每个点进行一次光线追踪计算，并将最终处理结果中和为一个颜色。这样能有效避免锯齿，当然带来的后果是处理时间进一步增加。

## 总结
以上便是对Ray Tracing in One Weekend的主要内容做一个粗略的描述了。具体实现上还有很多细节需要处理，比如说相机的fov设置，对焦以及场景虚化；不同材质的计算方式等等，这些还是需要对原文章进行仔细研读才行。